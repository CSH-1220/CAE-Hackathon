{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input the evaluation image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './Evaluation Dataset Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results from classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /Data/home/Dennis/CV_in_Construction/CAE_hackathon/MainCategoryClassification/Evaluation Dataset Images/_classes.csv\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb71ab83e80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "from utils_RHM.tools import process_directory, process_dataset, load_saved_model\n",
    "import torch\n",
    "process_directory(img_dir)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "img_data , model = process_dataset(img_dir,device)\n",
    "model = load_saved_model('./pretrained_model/classification.pt',model)\n",
    "from utils_RHM.tools import evaluate_model\n",
    "all_predictions = evaluate_model(img_data , model , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "threshold = 0.5\n",
    "data = []\n",
    "category_info = {'Aeration':0, 'Discolouration_colour':1, 'Discolouration_Outfall':2,'Wildlife_Fish': 3,'Modified_Channel':4, 'Obstruction':5,\n",
    "                 'Outfall':6, 'Outfall_Aeration':7, 'Outfall_Screen':8, 'Outfall_Spilling':9,\n",
    "                 'Rubbish':10, 'Sensor':11, 'Wildlife_Algal':12, 'Wildlife_Birds':13,\n",
    "                 'Wildlife_Other':14}\n",
    "for idx, logits in enumerate(all_predictions):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    predicted_classes = np.where(probs >= threshold, 1, 0)\n",
    "    ID = os.path.basename( img_data.dataset.img_path[idx])\n",
    "    ID = os.path.splitext(ID)[0]\n",
    "    row = {'ImageID': ID}\n",
    "    for category, index in category_info.items():\n",
    "        row[category] = predicted_classes[index]\n",
    "    data.append(row)\n",
    "\n",
    "df_prediction = pd.DataFrame(data)\n",
    "df_submision = pd.read_csv('./Evaluation Dataset Images/Hackathon Model Evaluation submission.csv')\n",
    "import pandas as pd\n",
    "merged_df = pd.merge(df_submision, df_prediction, on='ImageID', how='left', suffixes=('', '_df2'))\n",
    "for column in df_submision.columns:\n",
    "    if column != 'ImageID':\n",
    "        if column in df_prediction.columns:\n",
    "            df_submision[column] = merged_df[column + '_df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate the ratio of aeration, modified channel, obstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "def yolo_predict(image_path, specific_classes, device):\n",
    "    model = YOLO('./pretrained_model/object_detection.pt').to(device)\n",
    "    results = model(image_path,verbose=False)\n",
    "    yolo_boxes = []\n",
    "    for result in results:\n",
    "        for box, class_id in zip(result.boxes.xyxy, result.boxes.cls):\n",
    "            x1, y1, x2, y2 = box[:4]\n",
    "            class_id = class_id.item()\n",
    "            if class_id in specific_classes:\n",
    "                yolo_boxes.append((x1.item(), y1.item(), x2.item(), y2.item(), class_id))\n",
    "    return yolo_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.models.segmentation as segmentation\n",
    "def deeplab_predict(image_path, device):\n",
    "    deeplab_model = segmentation.deeplabv3_resnet101(weights=segmentation.DeepLabV3_ResNet101_Weights.DEFAULT)\n",
    "    deeplab_model.classifier[4] = torch.nn.Conv2d(256, 1, kernel_size=(1,1), stride=(1,1))\n",
    "    deeplab_model.load_state_dict(torch.load('./pretrained_model/river_segmentation.pth'))\n",
    "    deeplab_model.to(device)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    deeplab_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = deeplab_model(input_tensor)['out']\n",
    "    pred_mask = output[0].cpu().squeeze()\n",
    "    return pred_mask > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(yolo_boxes, mask, class_coefficients):\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    mask_area = np.sum(mask_np)\n",
    "    overlap_ratios = {}\n",
    "\n",
    "    for box in yolo_boxes:\n",
    "        x1, y1, x2, y2, class_id = box\n",
    "        box_mask = np.zeros_like(mask_np)\n",
    "        box_mask[int(y1):int(y2), int(x1):int(x2)] = 1\n",
    "\n",
    "        intersection = np.logical_and(box_mask, mask_np)\n",
    "        overlap_area = np.sum(intersection)\n",
    "        overlap_ratio = overlap_area / mask_area if mask_area > 0 else 0\n",
    "        if int(class_id) not in overlap_ratios:\n",
    "            overlap_ratios[int(class_id)] = 0\n",
    "        overlap_ratios[int(class_id)] += overlap_ratio * class_coefficients.get(int(class_id), 1.0)\n",
    "    return overlap_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_paths = []\n",
    "for root, dirs, files in os.walk(img_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.jpg'):\n",
    "            img_path = os.path.join(root, file)\n",
    "            img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "specific_classes = [0, 4, 5]\n",
    "data = []\n",
    "class_names = {0: 'Aeration_Extent', 4: 'Proportion_Modification', 5: 'Obstruction'}\n",
    "merged_ratios = {'Aeration_Extent': 0, 'Proportion_Modification': 0, 'Obstruction': 0}\n",
    "# 'Aeration_Extent', 'Proportion_Modification', 'Obstruction'\n",
    "for img_path in img_paths:\n",
    "    ID = os.path.basename( img_path)\n",
    "    ID = os.path.splitext(ID)[0]\n",
    "    row = {'ImageID': ID}\n",
    "    data.append(row)\n",
    "    yolo_boxes = yolo_predict(img_path, specific_classes, device)\n",
    "    mask = deeplab_predict(img_path, device)\n",
    "    class_coefficients = {0: 0.8, 4: 2, 5: 3}\n",
    "    overlap_ratios = calculate_overlap(yolo_boxes, mask, class_coefficients)\n",
    "    for class_id, ratio in overlap_ratios.items():\n",
    "        class_name = class_names[int(class_id)]\n",
    "        merged_ratios[class_name] += ratio\n",
    "    for category, index in merged_ratios.items():\n",
    "        row[category] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(data)\n",
    "df_prediction.loc[df_prediction['Proportion_Modification'] > 100, 'Proportion_Modification'] = 100\n",
    "df_prediction.loc[df_prediction['Aeration_Extent'] > 100, 'Aeration_Extent'] = 100\n",
    "df_prediction.loc[df_prediction['Obstruction'] > 100, 'Obstruction'] = 100\n",
    "merged_df = pd.merge(df_submision, df_prediction, on='ImageID', how='left', suffixes=('', '_df2'))\n",
    "for column in df_submision.columns:\n",
    "    if column != 'ImageID':\n",
    "        if column in df_prediction.columns:\n",
    "            df_submision[column] = merged_df[column + '_df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wildlife categopry compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Wildlife_Fish', 'Wildlife_Algal', 'Wildlife_Invertebrate','Wildlife_Birds','Wildlife_Other']\n",
    "condition = (df_submision[columns_to_check].notna() & (df_submision[columns_to_check] != 0)).any(axis=1)\n",
    "df_submision['Wildlife'] = np.where(condition, 1, df_submision['Wildlife'])\n",
    "df_submision['Wildlife'] = df_submision['Wildlife'].apply(lambda x: 0 if x != 1 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize different ratio of aeration, modified channel, obstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(value):\n",
    "    if value == 100:\n",
    "        return 'Full'\n",
    "    elif value >= 25:\n",
    "        return 'Partial'\n",
    "    elif value < 25 and value > 0:\n",
    "        return 'Minor'\n",
    "    elif value == 0:\n",
    "        return 'None'\n",
    "df_submision['Aeration_Extent'] = df_submision['Aeration_Extent'].apply(categorize)\n",
    "df_submision['Proportion_Modification'] = df_submision['Proportion_Modification'].apply(categorize)\n",
    "df_submision['Obstruction'] = df_submision['Obstruction'].apply(categorize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submision.to_csv('Model_Evaluation_Submission_Team1_Final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
